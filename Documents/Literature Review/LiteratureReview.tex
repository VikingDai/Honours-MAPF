\documentclass[a4paper,11pt]{article}

% set up sensible margins (same as for cssethesis)
\usepackage[paper=a4paper,left=30mm,right=30mm,top=25mm,bottom=25mm]{geometry}
\usepackage{natbib} % Use the natbib bibliography and citation package
\usepackage{setspace} % This is used in the title page
\usepackage{graphicx} % This is used to load the crest in the title page
\usepackage{physics} % Used for \abs

% non-template packages
\usepackage{paralist}
\usepackage{multicol}
\usepackage{caption}
\usepackage{tabularx, booktabs}
\newcolumntype{Y}{>{\centering\arraybackslash}X}
\usepackage{listings}
\lstset{
	numbers=left, 
	numberstyle=\small, 
	numbersep=8pt, 
	frame = single, 
	language=Python, 
	framexleftmargin=17pt}

\usepackage{tikz}
\usepackage{smartdiagram}

\usepackage[font={small,it}]{caption}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{lscape}
\hypersetup{
	colorlinks,
	linkcolor=teal,
	citecolor=teal,
	urlcolor=blue
}

\usepackage[english]{babel}
\usepackage{blindtext}
\usepackage{footnote}
%\makesavenoteenv{tabular}
%\makesavenoteenv{table}

%tikz stuff
\usepackage{tikz}
\usetikzlibrary{shapes, arrows, trees}
\tikzstyle{decision} = [diamond, draw, fill=green!20, text width=4.5em, text badly centered, node distance=3cm, inner sep=0pt]
\tikzstyle{block} = [rectangle, draw, fill=yellow!20, text width=3cm, text centered, rounded corners, minimum height=4em]
\tikzstyle{line} = [draw, -latex']
\tikzstyle{straight} = [draw]


\usepackage{array}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

\usepackage{float}

%\hypersetup{
%	colorlinks,
%	linkcolor={red!50!black},
%	citecolor={blue!50!black},
%	urlcolor={blue!80!black}
%}

\begin{document}
	
% Set up a title page
\thispagestyle{empty} % no page number on very first page
% Use roman numerals for page numbers initially
\renewcommand{\thepage}{\roman{page}}

\begin{spacing}{1.5}
	\begin{center}
		{\Large \bfseries
			School of Computer Science (BICA) \\
			Monash University}
		
		
		\vspace*{30mm}
		
		\includegraphics[width=5cm]{graphics/MonashCrest.pdf}
		
		\vspace*{15mm}
		
		{\large \bfseries
			Literature Review, 2017
		}
		
		\vspace*{10mm}
		
		{\LARGE \bfseries
			Review of optimal multi-agent Pathfinding algorithms and usage in warehouse automation
		}
		
		\vspace*{20mm}
		
		{\large \bfseries
			Phillip Wong
			
			\vspace*{20mm}
			
			
			Supervisors: \parbox[t]{50mm}{Daniel Harabor,\\Pierre Le Bodic}
		}
		
	\end{center}
\end{spacing}

\newpage

\tableofcontents

\newpage
% Now reset page number counter,and switch to arabic numerals for remaining
% page numbers 
\setcounter{page}{1}
\renewcommand{\thepage}{\arabic{page}}

\section{Introduction} \label{sec:introduction}
% What
The order picking process is the number one expense in the operating cost of warehouse systems (\cite{de2007design}). Order picking involves the retrieval of inventory from around the warehouse.
This project looks at the use of multi-agent pathfinding (MAPF) algorithms within order picking. In particular, we will be exploring Kiva systems (\cite{wurman2008coordinating}) where the order-picking process is performed by autonomous vehicles.

Firstly we define the components making up a Kiva system (Figure~\ref{fig:kivaprocess}). \textit{Drive units} are our autonomous vehicles which move around the warehouse, retrieving and delivering shelving units. These shelving units are known as \textit{storage pods} and are usually organized in aisles. Lastly we have the \textit{picking station} where a human workers are situated. With these defined, the process of order picking in a Kiva system is as follows:
\begin{compactenum}
	\item An order is received requesting one or more products
	\item The system identifies storage pods containing the said products
	\item The system schedules drive units to pickup the storage pods
	\item Once a drive unit is ready, it will move to the storage pod, pick it up and deliver it to the correct picking station
	\item Once the drive unit has delivered the storage pod, a human worker situated at the picking station will pick the product off the storage pod and pack it into a box
	\item After the storage pod has been picked, the drive unit agent returns it to a suitable location
	\item Finally once all the products for the order have been packed, the box it is processed and sent off
\end{compactenum}

\noindent As this process describes, Kiva systems have more hard problems to solve than MAPF. Scheduling occurs when storage pods run low on products or drive unit agents run out of battery. Both of these have to be replenished, hence a schedule needs to be determined. Another example is a robotics problem described in the Amazon picking challenge (\cite{correll2016lessons}). The motivation of this challenge is replace the human worker with a robotic arm to perform the picking and packing and hence improve the reliability and speed of picking. 

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.6\textwidth ]{graphics/kivaprocess}
	\caption{A worker picking an order from a storage pod. The orange robot underneath is the drive unit. (\cite{kivayoutube2010quietlogistics})}
	\label{fig:kivaprocess}
\end{figure}

Solving all these problems and applying them in one solution has been done by the creators of Kiva systems but is unfortunately is not described in any literature. The consequences of optimizing these systems together would be very useful to see what has the most effect but is out of the scope of this project. We will solely be focusing on the MAPF aspect of this system.

We see that a MAPF problem arises when a drive unit agent retrieves, delivers or returns a storage pod. Here we need a solution to coordinate drive unit agents so they can move around the warehouse without colliding with other drive units. This is not a simple task as solving MAPF optimally is an NP-hard problem (\cite{yu2013structure}). We can conclude that Kiva systems in production are using a suboptimal algorithms as these warehouses run over 1000 agents and hence scaling up to that scale optimally on a NP-hard problem. Later in Section~\ref{sec:optimal}, we look at the performance of these optimal algorithms. This forms the motivation behind our project, to look at the benefits we may find in Kiva systems by using an optimal approach and what we will have to sacrifice for scalability.

The main contribution of this project is identifying which algorithms have been applied to a Kiva system setting, what conclusions they have drawn and what literature gaps exists. Additionally, we will compare the scalability of optimal and suboptimal MAPF algorithms and see how optimal algorithms have tried to bridge this gap.

% How
Section~\ref{sec:background} describes in detail the MAPF problem and according terminology. Section~\ref{sec:problemdef} formally outlines the Kiva system problem. Section~\ref{sec:suboptimal} describes some state-of-the-art suboptimal MAPF algorithms. Section~\ref{sec:optimal} looks at optimal MAPF algorithms. Section~\ref{sec:generalimprovements} looks at \textit{operator decomposition} and \textit{independence detection}, two techniques which can be applied to most MAPF with significant benefits. Finally Section~\ref{sec:discussion} discusses the findings of this literature review, identifying possible research gaps within Kiva systems.

%In order to find an optimal solution we will be using formulating the MAPF problem as a mixed integer program. Section~\ref{sec:optimal} will look at past approaches taken to MAPF.
% Why
%The aim of this literature review is to summarize the state-of-the-art in optimal MAPF, compare them to the scalability of suboptimal algorithms and identify which algorithms have been tested in a Kiva system environment.

\section{Background} \label{sec:background}
\subsection{Single-agent pathfinding} The single-agent pathfinding problem aims to find a path from start node to goal node. A detailed review of single agent search algorithms can be found in the \textit{grid-based path planning competition} (\cite{sturtevant2015grid}). The paper overviews all the entries to the competition and their relative performance. The algorithms are run on a number of game maps from \cite{sturtevant2012benchmarks} which are used for benchmarking and these maps are used in many MAPF benchmarks. These results from \cite{sturtevant2015grid} are a few years old but we are expecting new approaches from this year's GPPC.

In this project, we aim to look at two single-agent search algorithms: \textit{jump point search} (\cite{harabor2011online}) and \textit{compressed path databases} (\cite{strasser2015compressing}). \cite{botea2013pathfinding} outlines both these algorithms as other single-agent search techniques in the context of computer games.

\subsection{Multi-agent pathfinding} Here we briefly describe the general problem of MAPF, in Section~\ref{sec:problemdef} we will formally define the problem in the context of Kiva systems as well as outlining terminology. The task of the MAPF problem is to coordinate multiple agents moving around an environment. Each agent is a goal location and the algorithm is required to find a path for each agent while ensuring that agent collides with another. A common secondary objective is to minimize either the makespan of the system or the sum of individual costs (SIC). As mentioned in Section~\ref{sec:introduction}, solving MAPF optimally is an NP-hard problem (\cite{yu2013structure}). Suboptimal and optimal MAPF have vastly different properties in scalability and solution quality. Thus they are compared in different sections [\ref{sec:optimal}, \ref{sec:suboptimal}]. Below are some important properties of MAPF algorithms. Table~\ref{table:comparison} shows a comparison of these properties across the MAPF algorithms discussed in this literature review.

\noindent \textbf{Completeness:} the algorithm will return valid solution to the MAPF problem if one exists

\noindent \textbf{Solution quality:} solution quality is usually measured as the objective of makespan or sum of individual costs (SIC). Makespan is the number of timestep required from the start state to the goal state where all agents are at their goals. SIC is the sum of the number of timesteps taken for each individual agent to reach their goal.
\begin{compactitem}
	\item Optimal: finds the optimal path to the goal minimizing the objective
	\item Bounded suboptimal: given a optimal path cost of $C$, the cost of a bounded suboptimal solution, $B$ is guaranteed to be within $C$ and $w*C$ where $w$ is a user set parameter. Hence, $C \le B \le wC$.
	\item Suboptimal: finds a path to the goal with no guarantee of solution cost
\end{compactitem}

\noindent \textbf{Anonymous:} In an anonymous MAPF problem the goal location is interchangeable and any agent can be assigned to a goal in order to satisfy the MAPF problem.

\noindent \textbf{Anytime:} The search can spend more computation to improve the solution quality or number of solutions. It can stop earlier at any time and return a path.

\noindent \textbf{Centralized / Coupled:} A centralized algorithm looks at all agents together in planning paths, whereas in a decentralized algorithm, paths are found for one agent at time. A centralized approach is usually used in finding an optimal solution but is not scalable. Accordingly a decentralized approach scales up to many agents but is suboptimal and often non-complete.

\noindent \textbf{Success rate:} Success rate is often used as a measure of performance in optimal algorithms. It describes the percentage of instances which were capable of being solved within a fixed time $t$, usually set at 5 minutes.

\subsection{Bounded-suboptimal variants} 
A bounded suboptimal variant is a variant of an optimal MAPF algorithm. The defining feature of a bounded suboptimal variant is that we are able to guarantee that the cost of the bounded suboptimal solution, $B$ lies within the optimal cost $C$ and $w*C$ where $w$ is a user-defined parameter. A bounded suboptimal variant provides a way of trading speed for solution quality and is especially relevant this project as we want to find a middle ground between optimality and speed for Kiva systems. The optimal algorithms in \ref{sec:optimal} will mention any bounded suboptimal variants if they exist.

\noindent \textbf{Integer Linear Programming}. Integer Linear Programming (ILP) is an optimization technique. It looks at an objective function subject to a list of constraints and finds the optimal solution for each variable. \textbf{not sure what to write here?}

%\[C \le B \le w*C\]
%
%Our project is aiming to make a bounded suboptimal variant of our algorithm due to the large-scale of the simulation (Section~\ref{sec:background}). By adjusting $w$ we are able to relax the problem and find a solution faster at the loss of solution quality.

\section{Problem definition} \label{sec:problemdef}
This section will formally define the MAPF problem in the context of Kiva Systems. The goal of MAPF is to coordinate agents and find a path for each agent to their goal while ensuring that no path conflicts. Here, a path is a sequence of actions, where an action is one of $\{up, down, left, right, wait\}$. A path is said to conflict with another when on the same timestep: two agents share the same node or two agents cross the same edge.

The warehouse environment is modelled as a square grid map in order to reduce the complexity of the MAPF algorithm. This is a  Graph $G(V, E)$ where $V$ is the set of nodes on the grid map and $E$ is the set of edges between nodes. On this map we have the components of a Kiva system: storage pods, drive units and picking stations (Figure~\ref{fig:kivawarehouse}), hence these are:
\begin{compactitem}
	\item A set of picking stations, $P$, where for all $p \in P$, $location (p) \in V$
	\item A set of storage pods, $S$, where for all $s \in S$, $location (s) \in V$
	\item A set of drive units, $K$, where for all $k \in K$, $location(k) \in V$ and $goal(k) \in V$
\end{compactitem}

An aspect of Kiva systems which makes the MAPF problem hard is that there are a large number of robots within them, up to a density of 1 in 6. The space within the warehouse is also very constrained as the storage pods are setup in narrow aisles where only 1 drive unit may move down at a time. However, collision occurs between a drive unit and a storage pod only if a drive unit is carrying a storage pod. In other words, drive units are capable of maneuvering underneath storage pods. Additionally collision always occurs between drive units, picking stations and other drive units.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\textwidth]{graphics/kivasystemlayout}
	\caption{Kiva system represented on an orthagonal grid map (\cite{wurman2008coordinating})}
	\label{fig:kivawarehouse}
\end{figure}

Different to traditional the MAPF problem, the objective of a Kiva system is to minimize the down-time of human pickers. Kiva systems run 24 hours a day hence the Makespan and SIC are not quite representative as they require a goal-state. For MAPF algorithms which were applied to Kiva systems, we look at whether new objectives were used to measure performance.

\section{Suboptimal multi-agent pathfinding algorithms} \label{sec:suboptimal}
Suboptimal MAPF algorithms usually use a decentralized approach. In a decoupled approach, paths are found for one agent at time as oppose to a coupled approach which looks at all agents globally. These algorithms usually have the properties of being suboptimal and incomplete.

%\begin{center}
%\begin{tikzpicture}
%\centering
%\draw[step=1cm,gray,very thin] (0,0) grid (5,3);
%\fill[gray!] (0,0) rectangle (3,1);
%\node at (0.5, 2.5) {$a_2$};
%\node at (0.5, 1.5) {$a_1$};
%\end{tikzpicture}
%\end{center}

\subsection{Cooperative A*}
Cooperative A*
Exponential in number of agents

\cite{holte1995hierarchical}

\cite{silver2005cooperative} gives an overview of these three algorithms.

%\subsection{FAR}
%Flow Annotation Replanning (FAR) (Wang and Botea 2008) imposes unidirectional travel on top of an initially undirected gridmap. The travel direction alternates across the rows (and columns), covering the grid with criss- crossing virtual “road lanes”. Topology-specific additional rules, applied locally, preserve the connectivity across the map. In terms of map abstraction, this boils down to remov- ing some directed edges from a graph, as opposed to splitting a map into subgraphs. FAR computes a path for each unit independently, in a unit-centric decomposition. Conflicts, such as cycles, are addressed at runtime. A common idea with our work is restricting the traffic flow by ignoring some edges and imposing a travel direction on others. The flowin- side SDP high-contention areas is restricted as shown later in this paper. We take advantage of the specific topology of high-contention areas, ensuring that they are free from local deadlocks

\subsection{MAPP}
MAPP (\cite{wang2011mapp}) is a suboptimal algorithm which main benefit is its polynomial runtime complexity of $O(n^2k^2)$ where $n$ is the number of nodes on the graph and $k$ is the number of agents. It guarantees this by identifying sets of units which are guaranteed to run in polynomial time and is complete for slidable problems if there exists an $\Omega$ path for each agent (Figure~\ref{fig:omegapath}).

% MAPP that it does not require replanning.

\begin{figure}[H]
	\centering
	\includegraphics[width=\linewidth]{graphics/mappblank}
	\label{fig:mappblank}
	\caption{Example of how MAPP works (\cite{wang2011mapp})}
\end{figure}

In comparison to FAR and WHCA*, MAPP excels in having high completeness at 92\%--99.7\%, compared to FAR (81.87\%) and WHCA* (80.87\%). Speed-wise, MAPP is comparable to WHCA* and 10 times slower than FAR  but in scenarios where MAPP has $\Omega$ paths, MAPP is 2.18 times slower than FAR and 4.8--5.2 times faster than WHCA*.



\begin{figure}[H]
	\centering
	\includegraphics[width=0.4\linewidth]{graphics/omegapath}
	\label{fig:omegapath}
	\caption{An example of an alternate path, $\Omega$ (\cite{wang2011mapp})}
\end{figure}


\section{Optimal multi-agent pathfinding algorithms} \label{sec:optimal}
Optimal MAPF algorithms usually use a coupled approach also known as centralized approach. A coupled approach finds paths for all agents at once. 




Here we look at multi-agent pathfinding algorithms which aim to find the optimal solution based on some objective function. The objective function will be noted per algorithm. Our main aim is to determine the benefits and downsides of each algorithm.


Coupled approach: All agents at one! A* ICTS

\cite{krontiris2013feasibility} looked at the feasibility.

\subsection{Centralized A*}
Centralized A* is exponential in the number of agents $O(n^k)$

There are a number of algorithms based on Centralized A*, 

One variant of is an algorithm called enhanced partial A* expansion (EPEA*). The original algorithm \cite{yoshizumi2000partial}. An improvement on PEA* is EPEA* (\cite{felner2012partial}, \cite{goldenberg2014enhanced}).

Another variant is M*.

Independence Detection and Operator Decomposition provides an exponential speed up to Centralized A* as it reduces the number of agents being processed, more details about ID in Section~\ref{sec:od} and OD in Section~\ref{sec:od}.

\cite{ferner2013odrm} improves on M* by applying operator decomposition.

\subsection{Conflict based search} \label{sec:cbs}
The conflict-based search algorithm (\cite{sharon2015conflict}) relies on building a binary tree known as a  \textit{constraint tree} (CT). Each node in the CT describes a set of constraints, a solution and the cost of this solution. A constraint prohibits an agent $a$ from being at node $n$ at timestep $t$, in the form of $\langle a, n, t \rangle$.

A node in the CT is processed by finding the shortest path for each agent to their goal making sure to satisfy the constraints described by the node. If this path is not valid and a collision has occurred between two agents: $a_1, a_2$ then CBS branches and adds two successor nodes. Both successor nodes inherit the constraints of the parent node. Additionally the left successor will adds a new constraint $\langle a_1, n, t \rangle$ while the right node will add the constraint $\langle a_2, n, t \rangle$. CBS is optimal as it chooses the node to expand searching the constraint tree for the node with the lowest cost.

As CBS branches at every conflict, it is exponential in the number of conflicts. In comparison to EPEA*, CBS performed worse in maps with open spaces where sets of agents may be \textit{strongly coupled}, that is they frequent have a high rate of path conflicts between one another. On the other hand CBS was found to perform better in maps with bottlenecks, where A* would 


CBS is exponential in the number of conflicts In comparison to ICTS and A* CBS was found to be best in maps with bottlenecks (Fig.~\ref{cbsresults1}).

Here we look at a bounded-suboptimal variants of CBS were developed called iECBS \cite{cohen2016improved}, this algorithm improves on the past work which was known as ECBS (\cite{barer2014suboptimal}). iECBS expands on ECBS+HWY with the use of highways. iECBS was tested on a Kiva system domain of size $22 \times 54$ with 130 agents. This test did not model the Kiva problem described in Section~\ref{sec:problemdef}, instead the problem generated half the agents in Area1 and half the agents in Area2 of the map (\ref{fig:cbskivadomain}). Agents were then given a random goal location in the other area. Testing was performed against ECBS and found speedups in runtime of approximately 10 times.

\begin{figure}[!htb]
	\centering
	\centering
	\includegraphics[width=0.9\linewidth]{graphics/ecbskivadomain}
	\caption{Kiva-like domain with Area1 on the LHS and Area2 on the RHS (\cite{cohen2016improved})}
	\label{fig:cbskivadomain}
\end{figure}

%\begin{figure}[!htb]
%	\centering \tiny
%	\begin{minipage}{0.4\textwidth}
%	\centering
%	\includegraphics[width=\linewidth]{graphics/cbsresults1}
%	\caption{A Small Region of a Kiva Layout (\cite{sharon2015conflict}). Picking stations located on the left and storage pods laid out in rows.}
%	\label{cbsresults1}
%	\end{minipage}
%	\begin{minipage}{0.4\linewidth}
%		\centering
%	\includegraphics[width=\linewidth]{graphics/cbsresults1}
%	\caption{A Small Region of a Kiva Layout (\cite{sharon2015conflict}). Picking stations located on the left and storage pods laid out in rows.}
%	\label{cbsresults2}
%	\end{minipage}
%\end{figure}

Here CBS was compared against ICTS, EPEA*.

\subsection{Increasing Cost Search Tree}
This section describes the Increasing Cost Search Tree (ICTS) an optimal, complete MAPF algorithm (\cite{sharon2011increasing}). The ICTS algorithm generates a tree known as an \textit{increasing cost tree} (Figure~\ref{fig:increasingcosttree}). Each node in the tree describes a cost $C$ for each agent $[C_1,\dots,C_k]$. ICTS finds a valid solution when every agent $a_i$ is conflict-free and it generates these paths based off the cost described in the node by exploring all paths which are equal to $C_i$.  To build the tree, the root starts containing the an optimal cost disregarding any conflicts for each agent. When it does not find a valid solution, the algorithm will branch and generate $k$ successors, one for each agents. In each of the successors, the cost of $i$ will increment e.g. for successor 2: $[C_1,C_{2}+1,\dots,C_k]$. By exploring the tree in breadth-first manner, ICTS ends up with an optimal solution.

\begin{figure}[!htb]
	\centering
	\centering
	\includegraphics[width=0.9\linewidth]{graphics/ictstree}
	\caption{ICT for three agents (\cite{sharon2011increasing})}
	\label{fig:increasingcosttree}
\end{figure}

The ICT grows exponentially in $\Delta$, where delta is the difference between the optimal collision-free cost and the optimal cost which ignores collision (the root node). Hence the downfall of ICTS is an environment with many conflicts occurs or it is costly to resolve the conflicts, thus having a large $\Delta$. In comparison to $A*$ which is exponential in $k$, ICTS is exponential in $\Delta$ so it benefits most on open maps with many agents.

ICT was tested on the 

%\subsection{Integer Linear Programming}
%Integer Linear Programming (ILP) is an optimization technique. It looks at an objective function subject to a list of constraints and finds the optimal solution for each variable.
%
%\subsection{ILP (combined target-assignment and pathfinding)}
%\cite{ma2016optimal} covers the use of Network Flow, More details about the use of ILP is in Section~\ref{sec:tapf}.
%
%where agents are anonymous. 
%
%reduction to the integer multi- commodity flow problem on a time-expanded network.
%
%\cite{yu2016optimal} takes a Network Flow approach. The solver uses the branch-and-bound algorithm. Anytime approach.

%\subsection{ILP (Network Flow)}
%\cite{yu2013multi} connects multi-agent path planning on graphs (roadmaps) to network flow problems, showing that the former can be reduced to the latter, therefore enabling the application of combinatorial network flow algorithms, as well as general linear program techniques, to multiagent path planning problems on graphs.
%
%\cite{yu2016optimal} looks at Complete Algorithms and Effective Heuristics.
%
%\cite{yu2015optimal} looks at the Structure and Computational Complexity.

\subsection{Combined-target assignment and pathfinding} \label{sec:tapf}
This section describes the work by \cite{ma2016optimal}, which looks at developing MAPF algorithms for autonomous warehouse robots, they call this a combined assignment and pathfinding (TAPF) problem. Importantly the difference between a MAPF problem and a TAPF problem is that:

\begin{compactitem}
	\item Agents are split into teams and a team of $k$ agents will have $k$ goal locations
	\item Agents are anonymous: any agent in a team can be assigned to a goal location
\end{compactitem}

An important property is that anonymous MAPF problems are usually solved in polynomial time. This paper describes two algorithms which are made to solve the TAPF problem. Both of these at the low-level uses a a min-cost max-flow algorithm. First is conflict-based min-cost flow (CBM), a hierarchical algorithm and as the name describes uses CBS (\ref{sec:cbs}) at the high-level and  on the low-level. Next is ILP (TAPF), which is similar to CBM but instead of using CBS at the high level an ILP-based TAPF solver is used at the low-level. This ILP solver is based off the work by (\cite{yu2013multi}) and uses a network-flow approach. Results found that this solver performed worse than the ILP MAPF solver in runtime and success rate but won in makespan.

CBM is applied to Kiva Systems which is the motivation behind formulating the TAPF problem. Their problem instances for Kiva Systems contain 420 drive units moving to 7 picking stations, the total warehouse size was not stated. Results suggested that  was performed well enough to be used in real-world applications of Kiva systems, with an 80\% success rate, mean makespan of 63.83 seconds and mean running time of 91.61 seconds. Importantly the results beat that of bounded suboptimal MAPF algorithms which were designed for Kiva systems.

\section{Independence detection and operator decomposition} \label{sec:generalimprovements}
This section looks at two MAPF techniques developed by \cite{standley2010finding} which can be applied to most MAPF algorithms and provide significant speedups.

\textbf{Independence detection}. Independence detection (ID) finds independent groups of agents where it can be proven that these two groups will not be in conflict. These groups are split and treated as seperate subproblems. Importantly this reduces the number of agents and provides an exponential speed up for A* and a polynomial speedup for many non-A* based algorithms.

\textbf{Operator decomposition}. Operator decomposition (OD) reduces the branching factor by performs one agents action at a time as oppose to an operator applying to every agent simultaneously. OD gives a much deeper tree but with a much smaller branching factor. At every $k$ levels in the tree we get an equivalent state where OD would not be used and hence the branching factor can be seen as $a$ instead of $a^k$ where $a$ is the number of possible actions and $k$ is the number of agents.

\cite{standley2010finding} found that OD had larger benefits and scaled better than ID. Regardless they can both be used.

\section{Discussion} \label{sec:discussion}

\begin{table}
	\centering
	\small
	\begin{tabular}{ l c c c c c p{2.3cm}}
		
		\textbf{Name} & \textbf{BSV} & \textbf{Complete} & \textbf{Complexity} & \textbf{KS} & \textbf{Comparison} \\
		\hline
		\multicolumn{6}{l}{\textbf{Optimal}} \\
		\hline
		CBS 				& N & Y & Exp conflicts & Y & ICTS, EPEA* \\
		Centralized A* 		& Y & Y & Exp agents & N & ??? \\
		ICTS 				& Y & Y & Exp $\Delta$ & N & A*, A*+OD \\
		ILP	(NF)			& Y & Y & Exp conflicts & Y & CBS \\
		ILP	(TAPF)			& N & Y & Exp conflicts & Y & ILP (NF), IPL (TAPF) \\
		CBM 				& N & Y & Exp conflicts & Y & ILP (NF), IPL (TAPF) \\
		\hline
		\multicolumn{6}{l}{\textbf{Suboptimal}} \\
		\hline
		FAR  				& N & N & Poly & N & WHCA* \\
		MAPP 				& N & Y & Poly & N & WHCA*, FAR \\
		WHCA* 				& N & N & Poly & N & \\
	\end{tabular}

	\caption{Table comparing the stated algorithms and their properties. \textbf{BSV}: Does the algorithm have a bounded-suboptimal variant. \textbf{Complexity}: Runtime complexity. \textbf{KS}: has the algorithm been applied to Kiva systems. \textbf{Comparision}: the algorithms used for benchmark testing.}
	\label{table:comparison}
\end{table}

In regards to suboptimal algorithms, none were applied to Kiva systems. It would be useful to see the relative makespans of the system for a suboptimal solution for comparison against optimal solutions.

We found that most optimal algorithms improve scalability by relaxing the solution quality and creating a bounded-suboptimal variant. Two examples of these are iECBS~(\cite{cohen2016improved}) and EPEA*~(\cite{goldenberg2014enhanced}). These approaches definitely increase the scalability of the optimal algorithm by a factor of up to 5 times in the case of CBS. This allows for a solution to be found with 85\% success rate on a graph with 200 agents.

Another approach to improving scalability, \cite{ma2016optimal} finds large gains in defining a special case of the MAPF problem, the TAPF problem which applies to Kiva systems. The important difference here is that agents are anonymous. Their algorithm, CBM takes advantage of this formulation and is an optimal algorithm that can scale up to 450 agents with 80\% success rate. This optimal algorithm wins over even the bounded-suboptimal variants of CBS. This is a important development and it would be interesting to see if a bounded-suboptimal variant of CBM can be made and if the variant will provide benefits on the same scale as iECBS gives to CBS.  This gap seems like a good fit for our work and we look at these two techniques and applying them together, possibly scaling up to the 1000+ agents which is required by Kiva systems.

We find that in algorithms that look at Kiva systems, iECBS (\cite{cohen2016improved})  and CBM (\cite{ma2016optimal}), the downtime of human pickers is overlooked. In the case of CBM the algorithm takes a snapshot of the system and perform one cycle of the Kiva process. For ECBS, the algorithm simply looked at a Kiva-like environment and moved agents from one side to the other. For both papers, the objective was on makespan and success rate. Unlike the approach where CBM looks at snapshotting a instance of the Kiva system problem, we may look at generating $n$ number of orders and seeing how long the simulation takes to fulfill these orders, the SIC and the downtime. This approach would allow for the other problems within Kiva systems like scheduling to interact with the MAPF algorithm as described in \ref{sec:introduction}.

Lastly, related to both scalability and the objective of downtime: an optimal algorithm would allow for more shorter paths to be found compared to a suboptimal algorithm hence less agents would required to fulfill the same supply of inventory to human pickers. As less agents are required in the simulation, we can greatly reduce the complexity of the MAPF problem. Therefore there may be a balance of adjusting the solution quality to provide more efficient agents thus keeping the same supply of inventory, while reducing the complexity. We hope to look at this relation in detail and perhaps find a point where it is better to simply add more agents to increase supply or increase the efficiency of each agent.

\bibliographystyle{dcu}
\bibliography{bibliography}
	
\end{document}
